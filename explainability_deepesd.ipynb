{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c5f008e-3c02-4d7e-8c18-d5f98acd84e2",
   "metadata": {},
   "source": [
    "## Explainability of the DeepESD model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb14c8b-fedd-4986-bc45-c6da63727105",
   "metadata": {},
   "source": [
    "The `deep4downscaling` library includes the module `deep4downscaling.deep.xai`, which implements various functions for applying eXplainable Artificial Intelligence (XAI) techniques [1,2] to statistical downscaling models. It is specifically designed to explain the decisions made by deep learning models developed with `deep4downscaling`. However, with some adjustments, it can also be extended to models outside the scope of `deep4downscaling`. In this example, we explain the DeepESD model trained in the `downscaling_deepsd.ipynb` notebook for precipitation downscaling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e39fa9-f444-4cf1-969d-f8183210046d",
   "metadata": {},
   "source": [
    "### Set the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf0fece-5aca-4dda-b225-4d9312a94302",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/input'\n",
    "FIGURES_PATH = './figures'\n",
    "MODELS_PATH = './models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31ad4df3-e0a1-42b5-9809-406360f25b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import torch\n",
    "import captum\n",
    "\n",
    "import sys; sys.path.append('/home/jovyan/deep4downscaling')\n",
    "import deep4downscaling.viz\n",
    "import deep4downscaling.trans\n",
    "import deep4downscaling.deep.models\n",
    "import deep4downscaling.deep.xai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e734dd5a-e1ee-48de-95d8-ff5fb8813402",
   "metadata": {},
   "source": [
    "First, we reconstruct part of the preprocessing performed during the training of the model. This step is crucial because both the loading of the trained model and the computation of XAI-based diagnostics require the dimensions of the predictor and predictand, as well as the defined mask to work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a9d8bb6-4937-49ad-a894-6df0419cbc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no observations containing null values\n"
     ]
    }
   ],
   "source": [
    "# Load predictor\n",
    "predictor_filename = f'{DATA_PATH}/ERA5_NorthAtlanticRegion_1-5dg_full.nc'\n",
    "predictor = xr.open_dataset(predictor_filename)\n",
    "\n",
    "# Load predictand\n",
    "predictand_filename = f'{DATA_PATH}/pr_AEMET.nc'\n",
    "predictand = xr.open_dataset(predictand_filename)\n",
    "\n",
    "# Remove days with nans in the predictor\n",
    "predictor = deep4downscaling.trans.remove_days_with_nans(predictor)\n",
    "\n",
    "# Align both datasets in time\n",
    "predictor, predictand = deep4downscaling.trans.align_datasets(predictor, predictand, 'time')\n",
    "\n",
    "# Split data into training and test sets\n",
    "years_train = ('1980', '2010')\n",
    "years_test = ('2011', '2020')\n",
    "\n",
    "x_train = predictor.sel(time=slice(*years_train))\n",
    "y_train = predictand.sel(time=slice(*years_train))\n",
    "\n",
    "x_test = predictor.sel(time=slice(*years_test))\n",
    "y_test = predictand.sel(time=slice(*years_test))\n",
    "\n",
    "# Standardize the test predictors w.r.t. to the training ones\n",
    "x_test_stand = deep4downscaling.trans.standardize(data_ref=x_train, data=x_test)\n",
    "\n",
    "# Set predictand masking\n",
    "y_mask = deep4downscaling.trans.compute_valid_mask(y_train) \n",
    "\n",
    "y_train_stack = y_train.stack(gridpoint=('lat', 'lon'))\n",
    "y_mask_stack = y_mask.stack(gridpoint=('lat', 'lon'))\n",
    "\n",
    "y_mask_stack_filt = y_mask_stack.where(y_mask_stack==1, drop=True)\n",
    "y_train_stack_filt = y_train_stack.where(y_train_stack['gridpoint'] == y_mask_stack_filt['gridpoint'],\n",
    "                                             drop=True)\n",
    "# Convert data from xarray to numpy\n",
    "x_test_stand_arr = deep4downscaling.trans.xarray_to_numpy(x_test_stand)\n",
    "y_train_arr = deep4downscaling.trans.xarray_to_numpy(y_train_stack_filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb480834-69e9-40ac-a815-c72c8257ba96",
   "metadata": {},
   "source": [
    "Next, we set the device to be used for computing these metrics. It is important to note that XAI techniques require the gradients of the model to be computed exactly as they were during training. Therefore, we recommend running these computations on a GPU, if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b600ec7d-3e12-4bd9-8ae5-54043e2850d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58175965-8e1e-4486-8347-80eb66790d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model to explain\n",
    "model_name = 'deepesd_pr'\n",
    "model = deep4downscaling.deep.models.DeepESDpr(x_shape=x_test_stand_arr.shape,\n",
    "                                               y_shape=y_train_arr.shape,\n",
    "                                               filters_last_conv=1,\n",
    "                                               stochastic=False)\n",
    "model.load_state_dict(torch.load(f'{MODELS_PATH}/{model_name}.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf2276-5cbf-4415-99fe-d2a49a1b5a1a",
   "metadata": {},
   "source": [
    "### Explainability techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce4ac18-6250-49fa-9525-847e8789ad7a",
   "metadata": {},
   "source": [
    "The module `deep4downscaling.deep.xai` enables the computation of both saliency maps and various XAI diagnostics, which combine these saliency maps across time and/or spatial locations. Saliency maps can be generated using a range of techniques, such as standard saliency, attribution, or integrated gradients, among others (refer to [3] for an overview of these techniques in the context of statistical downscaling).\n",
    "\n",
    "By leveraging `captum`, a PyTorch-integrated XAI library, `deep4downscaling` provides users with access to a wide variety of techniques (see [4] for a comprehensive list). In this notebook, for simplicity, we focus on standard saliency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ad7e1c-d0f1-4e2d-9907-00ab51a2e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "xai_method = captum.attr.Saliency(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd6b1fe-d7b8-4fad-909d-f2f782dd6d66",
   "metadata": {},
   "source": [
    "#### Integrated Saliency Map (ISM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a8e67e-b0a2-4947-bc14-fc4fb3a49cba",
   "metadata": {},
   "source": [
    "The `deep4downscaling.deep.xai.compute_ism` function applies the chosen XAI technique to all time steps in the `xr.Dataset` provided as the input to the `data` argument. The computations are performed with respect to a specific grid point in the predictand, which can be specified using the `coord` argument. This argument expects a tuple containing the latitude and longitude coordinates of the grid point to explain. If the specified grid point does not exist, the function applies the XAI technique to the nearest grid point in space.\n",
    "\n",
    "It is important to note the role of the `postprocess` argument. By setting this to `True`, the saliency maps are postprocessed following the approach described in [5] to reduce artifacts such as noisy patterns and improve consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b5a2ea-bb91-48d5-964e-82d37aa60c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ISMs...\n"
     ]
    }
   ],
   "source": [
    "spatial_coord = (43.125797, -8.087920)\n",
    "ism = deep4downscaling.deep.xai.compute_ism(data=x_test_stand,\n",
    "                                            mask=y_mask.copy(deep=True),\n",
    "                                            model=model, device=device,\n",
    "                                            xai_method=xai_method,\n",
    "                                            coord=spatial_coord,\n",
    "                                            postprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a2c8792-15b8-4b37-9bc9-556cadbc2cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_plot = '01-02-2018'\n",
    "deep4downscaling.viz.multiple_map_plot(data=ism.sel(time=time_to_plot),\n",
    "                                       colorbar='hot_r',\n",
    "                                       output_path=f'./{FIGURES_PATH}/ism.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9842e5-efdb-4f01-82ff-664750b80845",
   "metadata": {},
   "source": [
    "In addition to applying the XAI technique, it is also possible to compute various XAI-based diagnostics tailored for statistical downscaling. Specifically, `deep4downscaling` implements the Aggregated Saliency Map (ASM) and the Saliency Dispersion Map (SDM). For more information on these diagnostics, we refer the user to [5] and the documentation of the respective functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9cdf99-0c28-44f7-8aba-abcb4aae3c5c",
   "metadata": {},
   "source": [
    "#### Aggregated Saliency Map (ASM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c613dfe2-2ad0-4d45-8a69-bcc7b81d0423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ASMs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [02:21<00:00,  2.36s/it]\n"
     ]
    }
   ],
   "source": [
    "time_slice = ('01-01-2011', '03-01-2011')\n",
    "asm = deep4downscaling.deep.xai.compute_asm(data=x_test_stand.sel(time=slice(*time_slice)),\n",
    "                                            mask=y_mask.copy(deep=True),\n",
    "                                            model=model, device=device,\n",
    "                                            xai_method=xai_method,\n",
    "                                            batch_size=1024,\n",
    "                                            postprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86b12257-7f8c-422a-ab00-3fffffe6b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep4downscaling.viz.multiple_map_plot(data=asm,\n",
    "                                       colorbar='hot_r',\n",
    "                                       output_path=f'./{FIGURES_PATH}/asm.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf921eb-b90d-4490-9970-7423fd9cfe89",
   "metadata": {},
   "source": [
    "#### Saliency Dispersion Map (SDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5557c62-0677-4224-be4c-5afb2e1f9163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing Haversine distances...\n",
      "Computing SDMs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [02:24<00:00,  2.40s/it]\n"
     ]
    }
   ],
   "source": [
    "time_slice = ('01-01-2011', '03-01-2011')\n",
    "sdm = deep4downscaling.deep.xai.compute_sdm(data=x_test_stand.sel(time=slice(*time_slice)),\n",
    "                                            mask=y_mask.copy(deep=True), var_target='pr',\n",
    "                                            model=model, device=device,\n",
    "                                            xai_method=xai_method,\n",
    "                                            batch_size=1024,\n",
    "                                            postprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f35386b-7b34-419c-94db-79ee154bd0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep4downscaling.viz.simple_map_plot(data=sdm,\n",
    "                                     var_to_plot='pr',\n",
    "                                     colorbar='Reds',\n",
    "                                     output_path=f'./{FIGURES_PATH}/sdm.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9714f5df-dae7-4c6f-ac43-a81e96f38815",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] Buhrmester, V., Münch, D., & Arens, M. (2021). Analysis of explainers of black box deep neural networks for computer vision: A survey. Machine Learning and Knowledge Extraction, 3(4), 966-989.\n",
    "\n",
    "[2] Das, A., & Rad, P. (2020). Opportunities and challenges in explainable artificial intelligence (xai): A survey. arXiv preprint arXiv:2006.11371.\n",
    "\n",
    "[3] González Abad, J. (2024). Towards explainable and physically-based deep learning statistical downscaling methods.\n",
    "\n",
    "[4] https://captum.ai/docs/attribution_algorithms\n",
    "\n",
    "[5] González‐Abad, J., Baño‐Medina, J., & Gutiérrez, J. M. (2023). Using explainability to inform statistical downscaling based on deep learning beyond standard validation approaches. Journal of Advances in Modeling Earth Systems, 15(11), e2023MS003641."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep4downscaling-gpu",
   "language": "python",
   "name": "deep4downscaling-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
